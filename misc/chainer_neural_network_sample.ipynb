{
 "metadata": {
  "name": "",
  "signature": "sha256:96e924bbcc425233ebc1d90e4f40224d4a7d19af2903e17ee8114c2eb1b62070"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# training neural netwoek with chainer\n",
      "This note is same as http://qiita.com/kenmatsu4/items/7b8d24d4c5144a686412\n",
      "\n",
      "\u3053\u306e\u30ce\u30fc\u30c8\u3067\u3084\u3063\u3066\u3044\u308b\u3053\u3068\u3002\n",
      "\n",
      "chainer\u3092\u5229\u7528\u3057\u3066\u3001neural network\u3092\u69cb\u7bc9\u3057\u3001\u8a13\u7df4\u3001\u8a55\u4fa1\u307e\u3067\u3092\u884c\u306a\u3046"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from sklearn.datasets import fetch_mldata\n",
      "from chainer import cuda, Variable, FunctionSet, optimizers\n",
      "import chainer.functions  as F\n",
      "import sys\n",
      "\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u78ba\u7387\u7684\u52fe\u914d\u964d\u4e0b\u6cd5\u3067\u5b66\u7fd2\u3055\u305b\u308b\u969b\u306e\uff11\u56de\u5206\u306e\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\n",
      "batchsize = 100\n",
      "\n",
      "# \u5b66\u7fd2\u306e\u7e70\u308a\u8fd4\u3057\u56de\u6570\n",
      "n_epoch   = 20\n",
      "\n",
      "# \u4e2d\u9593\u5c64\u306e\u6570\n",
      "n_units   = 1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# MNIST\u306e\u624b\u66f8\u304d\u6570\u5b57\u30c7\u30fc\u30bf\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n",
      "# #HOME/scikit_learn_data/mldata/mnist-original.mat \u306b\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u308b\n",
      "print 'fetch MNIST dataset'\n",
      "mnist = fetch_mldata('MNIST original')\n",
      "# mnist.data : 70,000\u4ef6\u306e784\u6b21\u5143\u30d9\u30af\u30c8\u30eb\u30c7\u30fc\u30bf\n",
      "mnist.data   = mnist.data.astype(np.float32)\n",
      "mnist.data  /= 255     # 0-1\u306e\u30c7\u30fc\u30bf\u306b\u5909\u63db\n",
      "\n",
      "# mnist.target : \u6b63\u89e3\u30c7\u30fc\u30bf\uff08\u6559\u5e2b\u30c7\u30fc\u30bf\uff09\n",
      "mnist.target = mnist.target.astype(np.int32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fetch MNIST dataset\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u624b\u66f8\u304d\u6570\u5b57\u30c7\u30fc\u30bf\u3092\u63cf\u753b\u3059\u308b\u95a2\u6570\n",
      "def draw_digit(data):\n",
      "    size = 28\n",
      "    plt.figure(figsize=(2.5, 3))\n",
      "\n",
      "    X, Y = np.meshgrid(range(size),range(size))\n",
      "    Z = data.reshape(size,size)   # convert from vector to 28x28 matrix\n",
      "    Z = Z[::-1,:]             # flip vertical\n",
      "    plt.xlim(0,27)\n",
      "    plt.ylim(0,27)\n",
      "    plt.pcolor(X, Y, Z)\n",
      "    plt.gray()\n",
      "    plt.tick_params(labelbottom=\"off\")\n",
      "    plt.tick_params(labelleft=\"off\")\n",
      "\n",
      "    plt.show()\n",
      "\n",
      "draw_digit(mnist.data[5])\n",
      "draw_digit(mnist.data[12345])\n",
      "draw_digit(mnist.data[33456])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u3092 N\u500b\u3001\u691c\u8a3c\u7528\u30c7\u30fc\u30bf\u3092\u6b8b\u308a\u306e\u500b\u6570\u3068\u8a2d\u5b9a\n",
      "N = 60000\n",
      "x_train, x_test = np.split(mnist.data,   [N])\n",
      "y_train, y_test = np.split(mnist.target, [N])\n",
      "N_test = y_test.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare multi-layer perceptron model\n",
      "# \u591a\u5c64\u30d1\u30fc\u30bb\u30d7\u30c8\u30ed\u30f3\u30e2\u30c7\u30eb\u306e\u8a2d\u5b9a\n",
      "# \u5165\u529b 784\u6b21\u5143\u3001\u51fa\u529b 10\u6b21\u5143\n",
      "# l1\u306b\u5165\u529b\u5c64\u3001l2\u306b\u4e2d\u9593\u5c64\u3001l3\u306b\u51fa\u529b\u5c64\u306e\u69cb\u6210\uff1f\n",
      "model = FunctionSet(l1=F.Linear(784, n_units),\n",
      "                    l2=F.Linear(n_units, n_units),\n",
      "                    l3=F.Linear(n_units, 10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Neural net architecture\n",
      "# \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u69cb\u9020\n",
      "def forward(x_data, y_data, train=True):\n",
      "    x, t = Variable(x_data), Variable(y_data)\n",
      "    # h\u306fhidden\u306e\u610f\u5473\n",
      "    # h1\u306f\u5165\u529b\u5c64\u3002\u5165\u529b\u306ex\u304b\u3089\u30c7\u30fc\u30bf\u3092\u53d7\u3051\u53d6\u3063\u3066\u3001\u7b2c1\u5c64\u76ee\u3092\u4f5c\u308b\n",
      "    h1 = F.dropout(F.relu(model.l1(x)),  train=train)\n",
      "    # h2\u306f\u4e2d\u9593\u5c64\u3002h1\u304b\u3089\u30c7\u30fc\u30bf\u3092\u53d7\u3051\u53d6\u3063\u3066\u3001\u4e2d\u9593\u5c64\u3092\u4f5c\u308b\n",
      "    h2 = F.dropout(F.relu(model.l2(h1)), train=train)\n",
      "    # \u4e2d\u9593\u5c64\u304b\u3089\u30c7\u30fc\u30bf\u3092\u53d7\u3051\u53d6\u3063\u3066\u3001\u51fa\u529b\u5c64\u306e\u4f5c\u6210\u3002\u51fa\u529b\u5c64\u3092\u4f5c\u308b\u3060\u3051\u306a\u306e\u3067\u3001dropout\u306a\u3057\n",
      "    y  = model.l3(h2)\n",
      "    # \u591a\u30af\u30e9\u30b9\u5206\u985e\u306a\u306e\u3067\u8aa4\u5dee\u95a2\u6570\u3068\u3057\u3066\u30bd\u30d5\u30c8\u30de\u30c3\u30af\u30b9\u95a2\u6570\u306e\n",
      "    # \u4ea4\u5dee\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u95a2\u6570\u3092\u7528\u3044\u3066\u3001\u8aa4\u5dee\u3092\u5c0e\u51fa\n",
      "    return F.softmax_cross_entropy(y, t), F.accuracy(y, t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# dropout(x, ratio=0.5, train=True) \u30c6\u30b9\u30c8\n",
      "# x: \u5165\u529b\u5024\n",
      "# ratio: 0\u3092\u51fa\u529b\u3059\u308b\u78ba\u7387\n",
      "# train: False\u306e\u5834\u5408\u306fx\u3092\u305d\u306e\u307e\u307e\u8fd4\u5374\u3059\u308b\n",
      "# return: ratio\u306e\u78ba\u7387\u30670\u3092\u30011\u2212ratio\u306e\u78ba\u7387\u3067,x*(1/(1-ratio))\u306e\u5024\u3092\u8fd4\u3059\n",
      "\n",
      "n = 50\n",
      "v_sum = 0\n",
      "for i in range(n):\n",
      "    x_data = np.array([1,2,3,4,5,6], dtype=np.float32)\n",
      "    x = Variable(x_data)\n",
      "    dr = F.dropout(x, ratio=0.6,train=True)\n",
      "\n",
      "    for j in range(6):\n",
      "        sys.stdout.write( str(dr.data[j]) + ', ' )\n",
      "    print(\"\")\n",
      "    v_sum += dr.data\n",
      "\n",
      "# output\u306e\u5e73\u5747\u304cx_data\u3068\u3060\u3044\u305f\u3044\u4e00\u81f4\u3059\u308b \n",
      "sys.stdout.write( str((v_sum/float(n))) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0, 0.0, 0.0, 0.0, 12.5, 0.0, \n",
        "0.0, 5.0, 7.5, 10.0, 0.0, 0.0, \n",
        "2.5, 0.0, 7.5, 10.0, 0.0, 15.0, \n",
        "0.0, 0.0, 0.0, 10.0, 0.0, 15.0, \n",
        "2.5, 5.0, 0.0, 0.0, 0.0, 0.0, \n",
        "2.5, 5.0, 0.0, 0.0, 0.0, 15.0, \n",
        "0.0, 0.0, 0.0, 0.0, 12.5, 15.0, \n",
        "0.0, 5.0, 0.0, 0.0, 0.0, 0.0, \n",
        "2.5, 5.0, 7.5, 10.0, 0.0, 15.0, \n",
        "2.5, 5.0, 7.5, 0.0, 12.5, 0.0, \n",
        "0.0, 0.0, 0.0, 0.0, 12.5, 0.0, \n",
        "0.0, 0.0, 7.5, 10.0, 12.5, 15.0, \n",
        "0.0, 0.0, 0.0, 10.0, 12.5, 15.0, \n",
        "0.0, 5.0, 0.0, 0.0, 0.0, 15.0, \n",
        "0.0, 5.0, 0.0, 0.0, 0.0, 0.0, \n",
        "0.0, 5.0, 0.0, 0.0, 0.0, 0.0, \n",
        "0.0, 5.0, 0.0, 0.0, 12.5, 0.0, \n",
        "0.0, 0.0, 7.5, 0.0, 12.5, 15.0, \n",
        "2.5, 5.0, 7.5, 0.0, 12.5, 15.0, \n",
        "0.0, 0.0, 0.0, 0.0, 12.5, 0.0, \n",
        "0.0, 0.0, 0.0, 10.0, 0.0, 15.0, \n",
        "2.5, 0.0, 0.0, 0.0, 0.0, 15.0, \n",
        "0.0, 5.0, 0.0, 0.0, 12.5, 15.0, \n",
        "2.5, 5.0, 7.5, 10.0, 0.0, 0.0, \n",
        "0.0, 5.0, 7.5, 0.0, 0.0, 15.0, \n",
        "0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
        "2.5, 5.0, 0.0, 0.0, 0.0, 15.0, \n",
        "2.5, 0.0, 7.5, 0.0, 12.5, 15.0, \n",
        "0.0, 0.0, 7.5, 0.0, 0.0, 15.0, \n",
        "0.0, 5.0, 7.5, 0.0, 0.0, 0.0, \n",
        "0.0, 0.0, 0.0, 10.0, 0.0, 15.0, \n",
        "2.5, 0.0, 0.0, 10.0, 12.5, 15.0, \n",
        "0.0, 5.0, 0.0, 0.0, 12.5, 0.0, \n",
        "0.0, 5.0, 0.0, 0.0, 0.0, 0.0, \n",
        "2.5, 0.0, 7.5, 0.0, 0.0, 15.0, \n",
        "0.0, 5.0, 0.0, 10.0, 0.0, 15.0, \n",
        "0.0, 0.0, 0.0, 0.0, 12.5, 15.0, \n",
        "0.0, 0.0, 7.5, 10.0, 0.0, 0.0, \n",
        "0.0, 5.0, 7.5, 0.0, 12.5, 0.0, \n",
        "0.0, 5.0, 0.0, 0.0, 0.0, 15.0, \n",
        "2.5, 0.0, 0.0, 0.0, 12.5, 0.0, \n",
        "2.5, 0.0, 7.5, 0.0, 0.0, 0.0, \n",
        "0.0, 5.0, 7.5, 10.0, 12.5, 0.0, \n",
        "2.5, 5.0, 0.0, 10.0, 0.0, 0.0, \n",
        "0.0, 0.0, 7.5, 0.0, 12.5, 0.0, \n",
        "0.0, 0.0, 0.0, 0.0, 12.5, 0.0, \n",
        "0.0, 0.0, 0.0, 0.0, 12.5, 0.0, \n",
        "2.5, 5.0, 0.0, 0.0, 0.0, 0.0, \n",
        "2.5, 0.0, 7.5, 0.0, 0.0, 15.0, \n",
        "0.0, 0.0, 7.5, 0.0, 0.0, 0.0, \n",
        "[ 0.85000002  2.4000001   3.          2.79999995  5.25        7.19999981]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Setup optimizer\n",
      "optimizer = optimizers.Adam()\n",
      "optimizer.setup(model.collect_parameters())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/chainer/function_set.py:47: FutureWarning: 'collect_parameters' is deprecated. You can pass FunctionSet itself to 'optimizer.setup'\n",
        "  warnings.warn(msg, FutureWarning)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_loss = []\n",
      "train_acc  = []\n",
      "test_loss = []\n",
      "test_acc  = []\n",
      "\n",
      "l1_W = []\n",
      "l2_W = []\n",
      "l3_W = []\n",
      "\n",
      "# Learning loop\n",
      "for epoch in xrange(1, n_epoch+1):\n",
      "    print 'epoch', epoch\n",
      "\n",
      "    # training\n",
      "    # N\u500b\u306e\u9806\u756a\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u4e26\u3073\u66ff\u3048\u308b\n",
      "    perm = np.random.permutation(N)\n",
      "    sum_accuracy = 0\n",
      "    sum_loss = 0\n",
      "    # 0\u301cN\u307e\u3067\u306e\u30c7\u30fc\u30bf\u3092\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3054\u3068\u306b\u4f7f\u3063\u3066\u5b66\u7fd2\n",
      "    for i in xrange(0, N, batchsize):\n",
      "        x_batch = x_train[perm[i:i+batchsize]]\n",
      "        y_batch = y_train[perm[i:i+batchsize]]\n",
      "\n",
      "        # \u52fe\u914d\u3092\u521d\u671f\u5316\n",
      "        optimizer.zero_grads()\n",
      "        # \u9806\u4f1d\u64ad\u3055\u305b\u3066\u8aa4\u5dee\u3068\u7cbe\u5ea6\u3092\u7b97\u51fa\n",
      "        loss, acc = forward(x_batch, y_batch)\n",
      "        # \u8aa4\u5dee\u9006\u4f1d\u64ad\u3067\u52fe\u914d\u3092\u8a08\u7b97\n",
      "        loss.backward()\n",
      "        optimizer.update()\n",
      "\n",
      "        train_loss.append(loss.data)\n",
      "        train_acc.append(acc.data)\n",
      "        sum_loss     += float(cuda.to_cpu(loss.data)) * batchsize\n",
      "        sum_accuracy += float(cuda.to_cpu(acc.data)) * batchsize\n",
      "\n",
      "    # \u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u8aa4\u5dee\u3068\u3001\u6b63\u89e3\u7cbe\u5ea6\u3092\u8868\u793a\n",
      "    print 'train mean loss={}, accuracy={}'.format(sum_loss / N, sum_accuracy / N)\n",
      "\n",
      "    # evaluation\n",
      "    # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u8aa4\u5dee\u3068\u3001\u6b63\u89e3\u7cbe\u5ea6\u3092\u7b97\u51fa\u3057\u6c4e\u5316\u6027\u80fd\u3092\u78ba\u8a8d\n",
      "    sum_accuracy = 0\n",
      "    sum_loss     = 0\n",
      "    for i in xrange(0, N_test, batchsize):\n",
      "        x_batch = x_test[i:i+batchsize]\n",
      "        y_batch = y_test[i:i+batchsize]\n",
      "\n",
      "        # \u9806\u4f1d\u64ad\u3055\u305b\u3066\u8aa4\u5dee\u3068\u7cbe\u5ea6\u3092\u7b97\u51fa\n",
      "        loss, acc = forward(x_batch, y_batch, train=False)\n",
      "\n",
      "        test_loss.append(loss.data)\n",
      "        test_acc.append(acc.data)\n",
      "        sum_loss     += float(cuda.to_cpu(loss.data)) * batchsize\n",
      "        sum_accuracy += float(cuda.to_cpu(acc.data)) * batchsize\n",
      "\n",
      "    # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u306e\u8aa4\u5dee\u3068\u3001\u6b63\u89e3\u7cbe\u5ea6\u3092\u8868\u793a\n",
      "    print 'test  mean loss={}, accuracy={}'.format(sum_loss / N_test, sum_accuracy / N_test)\n",
      "\n",
      "    # \u5b66\u7fd2\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092\u4fdd\u5b58\n",
      "    l1_W.append(model.l1.W)\n",
      "    l2_W.append(model.l2.W)\n",
      "    l3_W.append(model.l3.W)\n",
      "\n",
      "# \u7cbe\u5ea6\u3068\u8aa4\u5dee\u3092\u30b0\u30e9\u30d5\u63cf\u753b\n",
      "plt.figure(figsize=(8,6))\n",
      "plt.plot(range(len(train_acc)), train_acc)\n",
      "plt.plot(range(len(test_acc)), test_acc)\n",
      "plt.legend([\"train_acc\",\"test_acc\"],loc=4)\n",
      "plt.title(\"Accuracy of digit recognition.\")\n",
      "plt.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch 1\n",
        "train mean loss=0.282946755228, accuracy=0.913900001744"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.116831067282, accuracy=0.96370000422"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 2\n",
        "train mean loss=0.136799135823, accuracy=0.957983336747"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.100526847246, accuracy=0.969200003743"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 3\n",
        "train mean loss=0.108750285326, accuracy=0.965550005039"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0744056349911, accuracy=0.977000006437"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 4\n",
        "train mean loss=0.097354401742, accuracy=0.969700008134"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0752967389041, accuracy=0.97560000658"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 5\n",
        "train mean loss=0.0852617796115, accuracy=0.973750008345"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.073200535209, accuracy=0.978600003719"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 6\n",
        "train mean loss=0.0759592965129, accuracy=0.976183343033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0647832866799, accuracy=0.981300005317"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 7\n",
        "train mean loss=0.0716780803748, accuracy=0.977350010176"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0634753826584, accuracy=0.981300006509"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 8\n",
        "train mean loss=0.0663693781527, accuracy=0.979766677618"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0622241890786, accuracy=0.981700006127"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 9\n",
        "train mean loss=0.060432713536, accuracy=0.981233343581"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0640919523337, accuracy=0.982600004673"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 10\n",
        "train mean loss=0.0604598129432, accuracy=0.980200010141"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0609822153425, accuracy=0.983900005817"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 11\n",
        "train mean loss=0.0608075306473, accuracy=0.981883344452"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0640662597302, accuracy=0.983600004911"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 12\n",
        "train mean loss=0.0524289842914, accuracy=0.983683344026"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0663013356988, accuracy=0.980600004792"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 13\n",
        "train mean loss=0.0506654234725, accuracy=0.984450009863"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0712667570916, accuracy=0.982300006151"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 14\n",
        "train mean loss=0.0535267602335, accuracy=0.983800010582"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0663717152138, accuracy=0.983000007272"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 15\n",
        "train mean loss=0.0505337899607, accuracy=0.984083344042"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0657385025873, accuracy=0.984200006723"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 16\n",
        "train mean loss=0.046007668146, accuracy=0.98593334347"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0596494497775, accuracy=0.985200007558"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 17\n",
        "train mean loss=0.0502694949023, accuracy=0.984933344324"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0718206059286, accuracy=0.983100004196"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 18\n",
        "train mean loss=0.0478252318555, accuracy=0.986266677181"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0699532201683, accuracy=0.982200005651"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 19\n",
        "train mean loss=0.0442139712725, accuracy=0.987083342473"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0646084836715, accuracy=0.983600007296"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 20\n",
        "train mean loss=0.042232687337, accuracy=0.98765000989"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test  mean loss=0.0711794714434, accuracy=0.983300008178"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}